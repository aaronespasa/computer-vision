---
layout: post
title: "Teoría"
category: yolo
author: aaron
---

{% assign imgUrl = "/assets/7.Yolo/" | prepend: site.baseurl%}



# YOLO (You Only Look Once)

Es un algoritmo de detección de objetos en tiempo real el cual evita gastar mucho tiempo no generando region proposals.

Prioriza la velocidad y reconocer los objetos a localizarlos perfectamente.

```python
# Representación de las clases en el output y

# c1 = person
# c2 = cat
# c3 = dog

# Para ubicar al objeto en un bounding box deberemos añadirle
# al output las coordenadas que determinen el tamaño de este:
# x, y, w, h
# x e y utilizarán el contexto de la celda (con valores entre 0 y 1)
# w y h el contexto de la imagen en general

# Además, le añadiremos al inicio un parámetro Pc que determina
# si existe un objeto en la imagen o no (0 o 1)

y = [Pc, c1, c2, c3, x, y, w, h]
```

Para detectar objetos podríamos utilizar el Sliding Windows Approach desplazando una ventana a lo largo de la imagen (utilizando ventanas de distintos tamaños) y verificando si existen objetos en cada una de las ventanas creadas. Sin embargo esto requeriría más tiempo de computación.

Una forma de agilizar este proceso sería haciendo que cada región cubriese una parte de la imagen sin superponerse, dando lugar a una rejilla o **grid**. Este es el procedimiento en el que se fundamenta YOLO.

<img src="{{ "yolo_grid.png" | prepend: imgUrl }}" class="md_image"/>

<p style="text-align:center">Representación del output de dos anchor boxes - Imagen de <a href="https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/" target="_blank">Paperspace Blog</a></p>

<br/>

Como podemos ver en la image superior cada celda posee un vector asociado (idéntico al vector "y" visto en la celda de código, solo que con el nombre "g<sub>n</sub>" con n siendo el número de la celda).

Al pasar cada celda por la CNN la dimensión de la imagen pasa a tener una profundida del tamaño del vector. Es decir, para un vector asociado de 3 clases (8 elementos): (ancho x alto x 8).

###### Non-Maximal Suppression

El problema con este método es que la CNN necesitará varias celdas para detectar al mismo objeto y acabaremos con múltiples bounding boxes del mismo objeto. Para solucionarlo, se utiliza la técnica **Non-Maximal Suppression** que trata de encontrar la bounding box que mejor representa al objeto de la imagen.

Para poder entender este concepto debemos conocer el **Intersection over Union** (IoU) en el que comparamos el "ground truth box" (el bounding box que debería estar seleccionada) con el área predicha. Para obtener su valor utilizamos la siguiente ecuación:

<img src="{{ "iou_equation.png" | prepend: imgUrl }}" class="md_image"/>

<p style="text-align:center">Ecuación del Intersection over Union</p>

Non-maximal suppression seleccionará solamente el bounding box con mayor valor de p<sub>c</sub> y deshará de las cajas que son muy similares a las seleccionadas. Por lo tanto, se le llama de esta manera ya que suprime todas las cajas que no tienen la máxima probabilidad de detección de un objeto.

###### Anchor boxes

¿Pero que ocurre si tenemos un objeto superponiendo a otro? Para solucionar esto utilizamos los **anchor boxes** para alcanzar los múltiples tamaños que tienen los objetos que queremos detectar. Estos los representamos de la siguiente manera:



<img src="{{ "anchor_boxes.png" | prepend: imgUrl }}" class="md_image"/>

<p style="text-align:center">Representación del output de dos anchor boxes - Imagen de Udacity</p>

Aunque los anchor boxes no funcionan muy bien con dos cajas superponiéndose que incluyan objetos del mismo tiempo, por ejemplo, dos personas.

#### Resumen y procedimiento del algoritmo YOLO

1. Una vez le damos una imagen del test dataset, YOLO la descompondrá formando un grid.
2. La CNN produce los output vectors de cada celda.
3. Tendremos gran cantidad de anchor boxes en la imagen, por lo que tendremos que utilizar el Non-Maximal Suppression dotándole de un cierto umbral para solamente seleccionar los objetos que lo superen para cada clase. Tras esto, de los bounding boxes seleccionados elimina los que son muy parecidos al que tiene mayor valor de p<sub>c</sub>.

[Paper de la versión 3 de YOLO](https://pjreddie.com/media/files/papers/YOLOv3.pdf)